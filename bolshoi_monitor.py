import requests
from bs4 import BeautifulSoup
import hashlib
import os
import sys

def load_seen_ads():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        with open('seen_ads.txt', 'r') as f:
            return set(line.strip() for line in f if line.strip())
    except FileNotFoundError:
        return set()

def save_seen_ads(seen_ads):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ —Ñ–∞–π–ª"""
    with open('seen_ads.txt', 'w') as f:
        for item in seen_ads:
            f.write(item + '\n')

def send_telegram_message(message):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram"""
    TELEGRAM_BOT_TOKEN = os.environ['TELEGRAM_TOKEN']
    TELEGRAM_CHAT_ID = os.environ['TELEGRAM_CHAT_ID']
    
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': TELEGRAM_CHAT_ID,
        'text': message,
        'parse_mode': 'HTML'
    }
    
    try:
        response = requests.post(url, data=data, timeout=10)
        if response.status_code == 200:
            print(f"‚úÖ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {message[:50]}...")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ Telegram API: {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
        return False

def get_page_content():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    URL = "https://bolshoi.ru/news"
    KEYWORD = "–î–æ—Å—Ç—É–ø–Ω—ã–π –ë–æ–ª—å—à–æ–π"
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(URL, headers=headers, timeout=15)
        response.raise_for_status()
        print("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return response.text, KEYWORD
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
        return None, KEYWORD

def parse_news(html, keyword):
    """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Å–∞–π—Ç–∞"""
    soup = BeautifulSoup(html, 'html.parser')
    news_items = []
    
    # –†–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π
    selectors = [
        '.news-item',
        '.article-item', 
        '.news-list-item',
        '.news-block',
        '[class*="news"]',
        'a[href*="/news/"]',
        'a[href*="/about/press/"]'
    ]
    
    for selector in selectors:
        items = soup.select(selector)
        if items:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}, —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(items)}")
            
            for item in items:
                # –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                title_elem = item.find(['h1', 'h2', 'h3', 'h4', 'a']) or item
                title = title_elem.get_text(strip=True)
                
                # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏
                link_elem = item.find('a') or item
                link = link_elem.get('href', '') if hasattr(link_elem, 'get') else ''
                
                if title and len(title) > 10:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–∏ –≤ –∞–±—Å–æ–ª—é—Ç–Ω—É—é
                    if link and link.startswith('/'):
                        link = 'https://bolshoi.ru' + link
                    elif link and not link.startswith('http'):
                        link = 'https://bolshoi.ru' + link
                    
                    # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    full_text = f"{title} {item.get_text(strip=True)}".lower()
                    
                    news_items.append({
                        'title': title,
                        'link': link,
                        'full_text': full_text,
                        'content': item.get_text(strip=True)
                    })
            break
    
    return news_items

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üé≠ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ë–æ–ª—å—à–æ–≥–æ —Ç–µ–∞—Ç—Ä–∞ —á–µ—Ä–µ–∑ GitHub Actions")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
    seen_ads = load_seen_ads()
    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(seen_ads)} –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    html, keyword = get_page_content()
    
    if not html:
        print("üö® –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        return
    
    # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π
    news_list = parse_news(html, keyword)
    print(f"üì∞ –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(news_list)}")
    
    new_ads_found = False
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ—Å—Ç–∏
    for news in news_list:
        if keyword.lower() in news['full_text']:
            # –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ö–µ—à–∞ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏
            news_hash = hashlib.md5(f"{news['title']}{news['link']}".encode()).hexdigest()
            
            if news_hash not in seen_ads:
                print(f"üéâ –ù–ê–ô–î–ï–ù–ê –ù–û–í–ê–Ø –ó–ê–ü–ò–°–¨: {news['title']}")
                
                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Telegram
                message = (
                    f"üé≠ <b>–ù–û–í–û–ï –û–ë–™–Ø–í–õ–ï–ù–ò–ï '–î–æ—Å—Ç—É–ø–Ω—ã–π –ë–æ–ª—å—à–æ–π'!</b>\n\n"
                    f"<b>–ó–∞–≥–æ–ª–æ–≤–æ–∫:</b> {news['title']}\n"
                )
                
                if news['link']:
                    message += f"<b>–°—Å—ã–ª–∫–∞:</b> {news['link']}\n"
                
                message += f"\n‚è∞ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                if send_telegram_message(message):
                    seen_ads.add(news_hash)
                    new_ads_found = True
                    print(f"‚úÖ –ù–æ–≤–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∏—Å—Ç–æ—Ä–∏—é")
    
    if not new_ads_found:
        print("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π —Å –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏
    save_seen_ads(seen_ads)
    print(f"üíæ –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞. –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(seen_ads)}")
    
    print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

if __name__ == "__main__":
    main()
